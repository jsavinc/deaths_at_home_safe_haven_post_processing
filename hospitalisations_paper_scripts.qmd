---
title: "Hospitalisations paper scripts"
author: "Jan Savinc"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---


# Overview

Here I process data from the safe haven into neat tables and graphs for the hospitalisations paper


# Preliminaries

```{r}
library(tidyverse)
library(patchwork)
library(broom)  # for tidy()
library(tictoc)  # for timing
library(janitor)  # for some nice cleaning functions
# library(flowchart)  # for plotting a flowchart; not usable for me - it's good if you have raw data!
library(ggflowchart)  # for plotting a flowchart

source("./FUNCTIONS.R")  # load common functions

dir_output <- "C:/Users/40011625/OneDrive - Edinburgh Napier University/SCADR/covid_mortality_home/drafts/hospitalisations paper/"
```

## Functions & constants

```{r}
# specify the order of place of death
levels_place_of_death <- c("Hospital", "Home", "Care home", "All")

code_place_of_death_consistently <- function(data_tbl) {
  data_tbl %>%
    mutate(
      ## shorten to "Home"
      cat_place_of_death = if_else(cat_place_of_death == "Home & non-institution", true = "Home", false = cat_place_of_death),
      ## Shorten to "Care home"
      cat_place_of_death = if_else(cat_place_of_death == "Care home & other", true = "Care home", false = cat_place_of_death),
      cat_place_of_death = factor(cat_place_of_death, levels = levels_place_of_death)
    )
}

## helper function to merge all pre-pandemic years into one
merge_years_n <- function(data_tbl) {
  data_tbl %>%
    mutate(
      val_cohort_year = fct_collapse(.f = val_cohort_year, "2020-21" = c("2020-21"), other_level = "2015-20") %>%
        fct_relevel("2015-20")
    ) %>%
    group_by(val_cohort_year, .add = TRUE) %>%
    summarise(n = sum(n), .groups = "drop")
}
merge_years_m_sd <- function(data_tbl) {
  data_tbl %>%
    mutate(
      val_cohort_year = fct_collapse(.f = val_cohort_year, "2020-21" = c("2020-21"), other_level = "2015-20") %>%
        fct_relevel("2015-20")
    ) %>%
    group_by(val_cohort_year, .add = TRUE) %>%
    summarise(mean = weighted.mean(mean, n_deaths),
              sd = sd_pooled(sd, n_deaths),
              n_deaths = sum(n_deaths),  # retain the number of individuals in each merged category - for hypothesis testing later!
              .groups = "drop")
}
```


# Load data & wrangle

This may be slow as I'm reading from the X:/ drive.

## Regression data & AMEs

I've exported the model coefficients in a piecemeal fashion, so I'll load them in and merge into a big table containing coefficients for all the models I've made (except for OLS models - these should go into a separate table because they don't report ORs/IRRs).

The hospitalisations and LOS/days in hospital models were exported with the pandemic period as the reference period, as opposed to pre-pandemic, so I'll recalculate the intercept and pandemic coefficient for those. (the OLS models for the same were exported later, and already have the pre-pandemic as the reference level)

```{r}
## helper function to recalculate the intercept and coefficient for the pandemic
## period variable, in cases where the reference level was set to the pandemic
## variable
change_reference_to_prepandemic <- function(tbl_coef) {
  # new intercept = old intercept + pandemic coef
  tbl_coef$Coefficient[tbl_coef$variable == "(Intercept)"] <-
    tbl_coef$Coefficient[tbl_coef$variable == "(Intercept)"] +
    tbl_coef$Coefficient[tbl_coef$variable == "cat_cohort"]
  # new pandemic coefficient = negative old pandemic coef
  tbl_coef$Coefficient[tbl_coef$variable == "cat_cohort"] <-
    -tbl_coef$Coefficient[tbl_coef$variable == "cat_cohort"]
  
  # 95% CI, intercept = low CI of old intercept + low CI of old pandemic coef
  tbl_coef$CI_low[tbl_coef$variable == "(Intercept)"] <- 
    tbl_coef$CI_low[tbl_coef$variable == "(Intercept)"] +
    tbl_coef$CI_low[tbl_coef$variable == "cat_cohort"]
  # ditto for high CI limit
  tbl_coef$CI_high[tbl_coef$variable == "(Intercept)"] <-
    tbl_coef$CI_high[tbl_coef$variable == "(Intercept)"] +
    tbl_coef$CI_high[tbl_coef$variable == "cat_cohort"]
    
  # 95% CI, pandemic coefficient
  temp_lo_ci <- tbl_coef$CI_low[tbl_coef$variable == "cat_cohort"]  # save value, can't change two values simultaneously!
  tbl_coef$CI_low[tbl_coef$variable == "cat_cohort"] <- -tbl_coef$CI_high[tbl_coef$variable == "cat_cohort"]
  tbl_coef$CI_high[tbl_coef$variable == "cat_cohort"] <- -temp_lo_ci
  
  # change factor lvl
  tbl_coef$level[tbl_coef$variable == "cat_cohort"] <- "Pandemic"
  
  # recompute IRR
  tbl_coef$IRR[tbl_coef$variable == "(Intercept)"] <- exp(tbl_coef$Coefficient[tbl_coef$variable == "(Intercept)"])
  tbl_coef$IRR_CI_low[tbl_coef$variable == "(Intercept)"] <- exp(tbl_coef$CI_low[tbl_coef$variable == "(Intercept)"])
  tbl_coef$IRR_CI_high[tbl_coef$variable == "(Intercept)"] <- exp(tbl_coef$CI_high[tbl_coef$variable == "(Intercept)"])
  tbl_coef$IRR[tbl_coef$variable == "cat_cohort"] <- exp(tbl_coef$Coefficient[tbl_coef$variable == "cat_cohort"])
  tbl_coef$IRR_CI_low[tbl_coef$variable == "cat_cohort"] <- exp(tbl_coef$CI_low[tbl_coef$variable == "cat_cohort"])
  tbl_coef$IRR_CI_high[tbl_coef$variable == "cat_cohort"] <- exp(tbl_coef$CI_high[tbl_coef$variable == "cat_cohort"])
  
  return(tbl_coef)
}

rebase_numeric_variables <- function(tbl_coef) {
  tbl_coef %>%
    mutate(across(
      c(Coefficient, CI_low, CI_high),
      ~ case_when(
        variable == "amt_age" ~ .x * 10,
        variable == "val_elixhauser_index_vanwalraven" ~ .x * 5,
        variable == "amt_drive_to_hosp_mins" ~ .x * 15,
        TRUE ~ .x
      ))) %>%
    mutate(across(
      c(IRR, IRR_CI_low, IRR_CI_high),
      ~ case_when(
        variable == "amt_age" ~ .x^10,
        variable == "val_elixhauser_index_vanwalraven" ~ .x^5,
        variable == "amt_drive_to_hosp_mins" ~ .x^15,
        TRUE ~ .x
      ))) %>%
    mutate(
      variable = case_when(
        variable == "amt_age" ~ "amt_age_10",
        variable == "val_elixhauser_index_vanwalraven" ~ "val_elixhauser_index_vanwalraven_5",
        variable == "amt_drive_to_hosp_mins" ~ "amt_drive_to_hosp_mins_15",
        TRUE ~ variable
      )
    )
}

# note, the 'other' models are just loaded but won't be used as-is - I filter them to use parts for other lists of models
model_coefficients_other <- read_csv("X:\\R2090\\2021-0312 Deaths at home\\safe_haven_exports\\modelling_hospitalisations\\tbl_models_coefficients_other.csv")

model_coefficients_ols <- read_csv("X:\\R2090\\2021-0312 Deaths at home\\safe_haven_exports\\modelling_hospitalisations\\tbl_models_coefficients_ols.csv")

model_coefficients_poisson <-
  bind_rows(
    read_csv(file = "X:\\R2090\\2021-0312 Deaths at home\\safe_haven_exports\\modelling_hospitalisations\\tbl_models_hosp_poisson.csv") %>% mutate(model = "hosp_poisson") %>%
      change_reference_to_prepandemic %>%
      rebase_numeric_variables,
    read_csv(file = "X:\\R2090\\2021-0312 Deaths at home\\safe_haven_exports\\modelling_hospitalisations\\tbl_models_los_poisson.csv") %>% mutate(model = "los_poisson") %>%
      change_reference_to_prepandemic %>%
      rebase_numeric_variables,
    model_coefficients_other %>% filter(model == "discharge_poisson")
  ) %>%
  relocate(model)

model_coefficients_negbin <-
  bind_rows(
    read_csv(file = "X:\\R2090\\2021-0312 Deaths at home\\safe_haven_exports\\modelling_hospitalisations\\tbl_models_hosp_negbin.csv") %>% mutate(model = "hosp_negbin") %>%
      change_reference_to_prepandemic %>%
      rebase_numeric_variables,
    read_csv(file = "X:\\R2090\\2021-0312 Deaths at home\\safe_haven_exports\\modelling_hospitalisations\\tbl_models_hosp_negbin.csv") %>% mutate(model = "los_poisson") %>%
      change_reference_to_prepandemic %>%
      rebase_numeric_variables,
    model_coefficients_other %>% filter(model == "discharge_negbin")
  )

# TODO: load the ZINB models... will need some work figuring out how to recalculate the reference level there?
model_coefficients_zinb <- NULL

model_coefficients_rse <- read_csv("X:\\R2090\\2021-0312 Deaths at home\\safe_haven_exports\\modelling_hospitalisations\\tbl_models_coefficients_rse.csv") %>%
  # rename so it's in line with the other outputs above
  rename(IRR = estimate, IRR_CI_low = conf.low, IRR_CI_high = conf.high, SE = std.error, z = statistic, p = p.value) %>%
  mutate(Coefficient = log(IRR), CI_low = log(IRR_CI_low), CI_high = log(IRR_CI_high))

model_ames <- read_csv("X:\\R2090\\2021-0312 Deaths at home\\safe_haven_exports\\modelling_hospitalisations\\tbl_models_ames.csv")

## load cohort size by PoD
cohort_by_pod <- 
  read_csv(file = "X:/R2090/2021-0312 Deaths at home/outputs/cohort_size_pod.csv") %>%
  repeat_data_adding_a_catchall_category(var_to_change = cat_place_of_death, label_for_catchall = "All") %>%
  group_by(val_cohort_year, cat_place_of_death) %>%
  summarise(n=sum(n), .groups = "drop")
  # code_place_of_death_consistently

## number of data with missing entries in home deaths  
missingness_home <- read_csv("X:\\R2090\\2021-0312 Deaths at home\\safe_haven_exports\\modelling_hospitalisations\\tbl_missingness.csv")

## number of people with/without hospitalisations - used for reporting sample size in days between discharge and death model
# Note: I just copied this manually from the reports, part 1 & part 2, modeling hospitalisations

## univariate regression coefficients, Poisson + RSE
univariate_regression_poisson_rse <- read_csv("X:\\R2090\\2021-0312 Deaths at home\\safe_haven_exports\\modelling_hospitalisations\\tbl_univariate_regressions_poisson_rse.csv") %>%
  # some basic wrangling to get the format to be the same as other outputs
  mutate(
    variable = str_extract(term, pattern = paste0(unique(model_coefficients_rse$variable), collapse = "|")),
    variable = if_else(term == "(Intercept)", term, variable),
    level = str_remove(term, pattern = paste0(unique(model_coefficients_rse$variable), collapse = "|")),
    level = if_else(term == "(Intercept)", "", level)
    ) %>%
  select(-term) %>%
  relocate(variable, level)

## univariate regression coefficients, negative binomial
univariate_regression_negbin <- read_csv("X:\\R2090\\2021-0312 Deaths at home\\safe_haven_exports\\modelling_hospitalisations\\tbl_univariate_regressions_negbin.csv") %>%
  # some basic wrangling to get the format to be the same as other outputs
  mutate(
    variable = str_extract(term, pattern = paste0(unique(model_coefficients_rse$variable), collapse = "|")),
    variable = if_else(term == "(Intercept)", term, variable),
    level = str_remove(term, pattern = paste0(unique(model_coefficients_rse$variable), collapse = "|")),
    level = if_else(term == "(Intercept)", "", level)
    ) %>%
  select(-term) %>%
  relocate(variable, level)
```

## Demographics & descriptives

```{r}
## load cohort size by PoD
cohort_by_pod <- 
  read_csv(file = "X:/R2090/2021-0312 Deaths at home/outputs/cohort_size_pod.csv") %>%
  repeat_data_adding_a_catchall_category(var_to_change = cat_place_of_death, label_for_catchall = "All") %>%
  group_by(val_cohort_year, cat_place_of_death) %>%
  summarise(n=sum(n), .groups = "drop") %>%
  code_place_of_death_consistently

sex_by_pod <- 
  read_csv(file = "X:/R2090/2021-0312 Deaths at home/safe_haven_exports/service_usage_by_cause_of_death/deaths_pod_cod_underlying_sex.csv") %>%
  filter(cat_cod_nrs == "All causes") %>%
  select(-cat_cod_nrs) %>%  # won't need this for now
  pivot_annual_to_long() %>%
  parse_n_prop(col_n_prop = n_prop) %>%
  code_place_of_death_consistently

sex_by_pod_2 <-
  sex_by_pod %>%
  left_join(cohort_by_pod %>% rename(denominator = n), join_by(val_cohort_year, cat_place_of_death)) %>%
  rename(
    n_female = n,
    prop_female = prop
    ) %>%
  mutate(
    n_male = denominator - n_female,
    prop_male = 1 - prop_female
    ) %>%
  (function(x){
    bind_rows(
      x %>% select(1:2, n = n_female, prop = prop_female) %>% mutate(cat_sex = "female"),
      x %>% select(1:2, n = n_male, prop = prop_male) %>% mutate(cat_sex = "male")
    )
  }) %>%
  mutate(cat_sex = factor(cat_sex)) %>%
  relocate(cat_sex, .after = val_cohort_year)

age_by_pod <- 
  read_csv(file = "X:/R2090/2021-0312 Deaths at home/safe_haven_exports/imgs2022_preliminary_results/descriptives_age_cohort_pod.csv") %>%
  code_place_of_death_consistently

age_group_by_pod <- 
  read_csv(file = "X:/R2090/2021-0312 Deaths at home/safe_haven_exports/associations with home death, logistic regression/part 3/tbl_age_decades_by_pod.csv") %>%
  code_place_of_death_consistently %>%
  mutate(cat_age_decades = factor(cat_age_decades))

marstat_by_pod <- read_csv(file = "X:/R2090/2021-0312 Deaths at home/safe_haven_exports/exploratory_descriptives/marstat_by_pod.csv") %>%
  pivot_annual_to_long() %>%
  parse_n_prop(col_n_prop = n_prop) %>%
  mutate(cat_marital_status_condensed = factor(cat_marital_status_condensed, levels = unique(cat_marital_status_condensed))) %>%
  code_place_of_death_consistently

ethnicity_by_pod <- read_csv(file = "X:/R2090/2021-0312 Deaths at home/safe_haven_exports/exploratory_descriptives/ethnicity_by_pod.csv") %>%
  pivot_annual_to_long() %>%
  parse_n_prop(col_n_prop = n_prop) %>%
  mutate(cat_ethnic_group_collapsed = factor(cat_ethnic_group_collapsed, levels = unique(cat_ethnic_group_collapsed))) %>%
  code_place_of_death_consistently

## rounded to nearest 10
simd_by_pod <-
  read_csv(file = "X:/R2090/2021-0312 Deaths at home/safe_haven_exports/imgs2022_preliminary_results/place_of_death_by_simd_and_cohort.csv") %>%
  pivot_annual_to_long() %>%
  parse_n_prop(col_n_prop = n_prop) %>%
  ## simd is reported as proportion of each simd quintile in each PoD, e.g. all
  ## PoDs in quintile 1 add up to 100%; so it needs rebased to proportion of
  ## quintiles within each PoD
  group_by(val_cohort_year, cat_place_of_death) %>%
  mutate(prop = n/sum(n)) %>%
  ungroup %>%
  code_place_of_death_consistently %>%
  mutate(cat_simd_quintile = factor(as.character(val_simd_quintile), levels = as.character(1:5)))

## load urban-rural table for the different level folds
urban_rural_reference <-
  read_csv(file = "X:/R2090/2021-0312 Deaths at home/safe_haven_exports/urban_rural_8_6_3_2_fold_table.csv") %>%
  mutate(across(everything(), ~factor(.x, levels = unique(.x))))


ur8_by_pod <-
  read_csv(file = "X:/R2090/2021-0312 Deaths at home/safe_haven_exports/imgs2022_preliminary_results/place_of_death_by_ur_and_cohort.csv") %>%
  pivot_annual_to_long() %>%
  parse_n_prop(col_n_prop = n_prop) %>%
  mutate(cat_ur8 = factor(cat_ur8, levels = unique(cat_ur8))) %>%
  ## ur is reported as proportion of each UR level by PoD; for this paper I think I need proportion of URs across each PoD
  group_by(val_cohort_year, cat_place_of_death) %>%
  mutate(prop = n/sum(n)) %>%
  ungroup %>%
  code_place_of_death_consistently

ur2_by_pod <-
  ur8_by_pod %>%
  left_join(urban_rural_reference, by = "cat_ur8") %>%
  group_by(val_cohort_year, cat_place_of_death, cat_ur2) %>%
  summarise(
    n = sum(n),
    prop = sum(prop),
    .groups = "drop"
  )

## this includes both number of comorbidities & elixhauser index
comorb_by_pod <- 
  read_csv(file = "X:/R2090/2021-0312 Deaths at home/safe_haven_exports/service_usage_by_cause_of_death/deaths_pod_comorb_index.csv") %>%
  pivot_annual_to_long(new_col = "mean_ci") %>%
  parse_m_ci(col_m_ci = mean_ci) %>%
  code_place_of_death_consistently %>%
  left_join(
    cohort_by_pod %>% rename(denominator = n),
    by = c("cat_place_of_death", "val_cohort_year")
  ) %>%
  recalculate_sd_from_mean_ci_and_n(mean_var = m, ci_lo_var = ci_lo, n_var = denominator, new_sd_var = sd)

# driving distance to nearest hospital
driving_by_pod <- read_csv("X:/R2090/2021-0312 Deaths at home/safe_haven_exports/distance_to_hospital_descriptives/distance_by_pod.csv") %>%
  filter(distance == "minutes") %>%
  code_place_of_death_consistently

# driving distance, grouped
driving_categorised_by_pod <- read_csv("X:/R2090/2021-0312 Deaths at home/safe_haven_exports/distance_to_hospital_descriptives/freq_distance_mins_by_pod.csv") %>%
  code_place_of_death_consistently %>%
  mutate(cat_drive_to_hosp_mins = factor(cat_drive_to_hosp_mins, levels=unique(cat_drive_to_hosp_mins))) %>%
  pivot_annual_to_long(new_col = "n_prop") %>%
  parse_n_prop(n_prop)

# causes of death by PoD
cod_by_pod <- read_csv(file = "X:/R2090/2021-0312 Deaths at home/safe_haven_exports/service_usage_by_cause_of_death/deaths_by_pod_cod_underlying (1).csv") %>%
  code_place_of_death_consistently %>%
  mutate(cat_cod_nrs = factor(cat_cod_nrs, levels=unique(cat_cod_nrs))) %>%
  pivot_annual_to_long(new_col = "n_prop") %>%
  parse_n_prop(n_prop)

# total days computed for everyone, including those not admitted
los_by_pod <- 
  read_csv(file = "X:/R2090/2021-0312 Deaths at home/safe_haven_exports/imgs2022_preliminary_results/descriptives_los_cohort_pod.csv") %>%
  code_place_of_death_consistently() %>%
  left_join(cohort_by_pod %>% rename(denominator = n), join_by(cat_place_of_death, val_cohort_year)) %>%
  mutate(
    mean_ci_lo = mean + qt(p = 0.025, df = n_admitted - 1) * sd /sqrt(n_admitted),
    mean_ci_hi = mean + qt(p = 0.975, df = n_admitted - 1) * sd /sqrt(n_admitted),
    ## adjust for proportion of 0s
    mean_adjusted = mean * denominator / n_admitted,
      sd_adjusted = sd * sqrt(denominator / n_admitted),
      mean_adjusted_ci_lo = mean_adjusted + qt(p = 0.025, df = n_admitted - 1) * sd_adjusted/sqrt(n_admitted),
      mean_adjusted_ci_hi = mean_adjusted + qt(p = 0.975, df = n_admitted - 1) * sd_adjusted/sqrt(n_admitted)
  )

# this is already reported with denominator including those with 0 hospitalisations
hosp_by_pod <- read_csv(file = "X:/R2090/2021-0312 Deaths at home/safe_haven_exports/exploratory_descriptives/smr01_spells_descriptives_by_pod.csv") %>%
  code_place_of_death_consistently()

# only individuals with 1+ hospitalisations included in this
dtdt_by_pod <- read_csv(file = "X:/R2090/2021-0312 Deaths at home/safe_haven_exports/exploratory_descriptives/dtdt_smr01_descriptives_by_pod.csv") %>%
  code_place_of_death_consistently()
```

## Missingness data

```{r}
missingness_overall <- read_csv(file = "X:/R2090/2021-0312 Deaths at home/safe_haven_exports/modelling_hospitalisations/tbl_missingness.csv") %>% select(val_cohort_year, any_missing) %>% parse_n_prop(col_n_prop = any_missing)

## individuals with no hospitalisations
no_hospitalisations <- read_csv(file = "X:/R2090/2021-0312 Deaths at home/safe_haven_exports/service_usage_by_cause_of_death/deaths_by_pod_cod_underlying_individuals_without_hosp.csv") %>%
  filter(cat_cod_nrs == "All causes") %>%
  pivot_annual_to_long() %>%
  parse_n_prop(col_n_prop = n_prop) %>%
  code_place_of_death_consistently
```



# Distribution graphs

```{r}
# TODO: load the graphs from the exploratory outputs before!
```

# Descriptives

This will need to combine demographics and outcome variables...

## Large table, combined numeric & categorical

### Categorical variables

```{r}
tbl_descriptives_data_categorical <-
  list(
    "Age group, N (%)" = age_group_by_pod %>% rename(levels = cat_age_decades),
    "Sex, N (%)" = sex_by_pod_2 %>% rename(levels = cat_sex),
    "Marital status, N (%)" = marstat_by_pod %>% rename(levels = cat_marital_status_condensed),
    "Ethnicity, N (%)" = ethnicity_by_pod %>% rename(levels = cat_ethnic_group_collapsed),
    "Deprivation, N (%)" = simd_by_pod %>% rename(levels = cat_simd_quintile),
    "Urban-rural classification, N (%)" = ur2_by_pod %>% rename(levels = cat_ur2),
    "Driving distance, N (%)" = driving_categorised_by_pod %>% rename(levels = cat_drive_to_hosp_mins),
    "Cause of death, N (%)" = cod_by_pod %>% rename(levels = cat_cod_nrs)
  )

tbl_descriptives_categorical_merged_years <-
  map(
    .x = tbl_descriptives_data_categorical,
    .f = function(data_tbl) {
      data_tbl %>%
        group_by(cat_place_of_death, levels) %>%
        merge_years_n() %>%
        group_by(cat_place_of_death, val_cohort_year) %>%
        mutate(prop = n/sum(n)) %>%
        ungroup
    }
  ) %>%
  list_rbind(names_to = "measure") %>%
  mutate(value = glue::glue("{scales::comma(n)} ({scales::label_percent(accuracy = 0.1)(prop)})")) %>%
  select(-c(n,prop)) %>%
  pivot_wider(names_from = val_cohort_year, values_from = value) %>%
  mutate(
    measure = factor(measure, levels = unique(measure)),
  ) %>%
  arrange(measure, cat_place_of_death)

# fisher's test of distributions within each PoD
tic()
tbl_fisher_test_categorical_descriptives <-
  map(
    # map over the components
    .x = 
      tbl_descriptives_data_categorical,
    .f = function(data_tbl) {
      data_tbl %>%
        group_by(cat_place_of_death, levels) %>%
        merge_years_n() %>%
        mutate(levels = fct_na_value_to_level(f = levels, level = "Missing")) %>%
        uncount(n) %>%
        nest(.by = cat_place_of_death) %>%
        mutate(
          test = map(
            .x = data,
            .f = function(data_tbl) {
              data_tbl %>% 
                tabyl(., levels, val_cohort_year, show_na = TRUE) %>%
                fisher.test(simulate.p.value = TRUE, B = 1e4) %>%
                tidy()
            }
          )
        ) %>% 
        select(-data) %>%
        unnest(test)
    }
  ) %>%
    list_rbind(names_to = "measure") %>%
    # replace_na() %>%  # TODO: what was I doing here?
    mutate(
      p_stars = gtools::stars.pval(p.value),
      p_pretty = scales::label_pvalue()(p.value)
    )
toc()

# save categorical table
tbl_descriptives_categorical_merged_years %>%
  left_join(tbl_fisher_test_categorical_descriptives %>% select(measure, cat_place_of_death, p_pretty), join_by(measure, cat_place_of_death)) %>%
  group_by(measure) %>%
  mutate(
    p_pretty = if_else(condition = duplicated(cat_place_of_death), true = " ", false = p_pretty)
  ) %>%
  ungroup(measure) %>%
  mutate(measure = if_else(condition = duplicated(measure), true = " ", false = as.character(measure))) %>%
  write_csv(., file = file.path(dir_output, "tbl_descriptives_categorical_merged_years.csv"))

# now also save a version with Home PoD only
tbl_descriptives_categorical_merged_years %>%
  left_join(tbl_fisher_test_categorical_descriptives %>% select(measure, cat_place_of_death, p_pretty), join_by(measure, cat_place_of_death)) %>%
  group_by(measure) %>%
  mutate(
    p_pretty = if_else(condition = duplicated(cat_place_of_death), true = " ", false = p_pretty)
  ) %>%
  ungroup(measure) %>%
  filter(cat_place_of_death=="Home") %>%
  select(-cat_place_of_death) %>%
  mutate(measure = if_else(condition = duplicated(measure), true = " ", false = as.character(measure))) %>%
  write_csv(., file = file.path(dir_output, "tbl_descriptives_categorical_merged_years_home_deaths_only.csv"))
```

### Numeric variables

```{r}
tbl_descriptives_data_numeric <- list(
  "Age, Mean (SD)" = age_by_pod,
  "Multimorbidity, Mean (SD)" = comorb_by_pod %>%
    filter(measure == "Elixhauser comorbidity index") %>%
    rename(mean = m, n_deaths = denominator),
  "Driving distance, Mean (SD)" = driving_by_pod %>%
    rename(mean = m, n_deaths = n),
  "Days in hospital, Mean (SD)" = los_by_pod %>% rename(n_deaths = n_admitted),
  "Number of hospitalisations, Mean (SD)" = hosp_by_pod %>%
    rename(mean = m, n_deaths = n_users),
  "Days between discharge and death, Mean (SD)" = dtdt_by_pod %>%
    left_join(hosp_by_pod %>% select(val_cohort_year, cat_place_of_death, n_deaths = n_users), join_by(cat_place_of_death, val_cohort_year)) %>%
    rename(mean = m)
)

tbl_descriptives_numeric_merged_years_with_ttest <-
  map(
    .x = tbl_descriptives_data_numeric,
    .f = function(data_tbl) {
      data_tbl %>%
        group_by(cat_place_of_death) %>%
        merge_years_m_sd() %>%
        mutate(
          broom::tidy(
          BSDA::tsum.test(
            mean.x = mean[1], s.x = sd[1], n.x = n_deaths[1],
            mean.y = mean[2], s.y = sd[2], n.y = n_deaths[2])
          ),
          p_stars = gtools::stars.pval(p.value),
          p_pretty = scales::label_pvalue()(p.value)
        ) %>%
        mutate(value = glue::glue("{signif(mean,3)} ({signif(sd,3)})"))
    }
  ) %>%
  list_rbind(names_to = "measure") %>%
  select(measure, cat_place_of_death, val_cohort_year, value, p_pretty) %>%
  pivot_wider(names_from = val_cohort_year, values_from = value) %>%
  mutate(
    measure = factor(measure, levels = unique(measure)),
  ) %>%
  arrange(measure, cat_place_of_death) %>%
  relocate(p_pretty, .after = ncol(.))

# save numeric table
tbl_descriptives_numeric_merged_years_with_ttest %>%
  mutate(measure = if_else(condition = duplicated(measure), true = " ", false = as.character(measure))) %>%
  write_csv(., file = file.path(dir_output, "tbl_descriptives_numeric_merged_years_with_ttest.csv"))

# now also save a version with Home PoD only
tbl_descriptives_numeric_merged_years_with_ttest %>%
  filter(cat_place_of_death=="Home") %>%
  select(-cat_place_of_death) %>%
  mutate(measure = if_else(condition = duplicated(measure), true = " ", false = as.character(measure))) %>%
  write_csv(., file = file.path(dir_output, "tbl_descriptives_numeric_merged_years_with_ttest_home_deaths_only.csv"))
```

## Outcomes by year & place of death

This is for the supplementary file as it's for context to the home decedents' data.

```{r}
tbl_descriptives_outcomes_by_year_pod_for_tbl <-
  bind_rows(
    los_by_pod %>%
      transmute(outcome = "Days in hospital", cat_place_of_death, val_cohort_year, m_sd = glue::glue("{signif(mean,3)} ({signif(sd,3)})")),
    hosp_by_pod %>%
  transmute(outcome = "Number of hospitalisations", cat_place_of_death, val_cohort_year, m_sd = glue::glue("{signif(m,3)} ({signif(sd,3)})")),
    dtdt_by_pod %>%
  transmute(outcome = "Days between final discharge & death", cat_place_of_death, val_cohort_year, m_sd = glue::glue("{signif(m,3)} ({signif(sd,3)})"))
  ) %>%
  pivot_wider(names_from = val_cohort_year, values_from = m_sd)

write_csv(tbl_descriptives_outcomes_by_year_pod_for_tbl, file =  file.path(dir_output, "tbl_descriptives_outcomes_by_year_and_pod.csv"))
```

## Figure: outcomes over time

```{r}
tbl_descriptives_outcomes_by_year_pod <-
  bind_rows(
    los_by_pod %>% select(cat_place_of_death, val_cohort_year, mean, sd, mean_ci_lo, mean_ci_hi) %>% mutate(outcome = "Days in hospital"),
    hosp_by_pod %>% select(cat_place_of_death, val_cohort_year, mean = m, sd, mean_ci_lo = ci_lo, mean_ci_hi = ci_hi) %>% mutate(outcome = "Number of\n hospitalisations"),
    dtdt_by_pod %>% select(cat_place_of_death, val_cohort_year, mean = m, sd, mean_ci_lo = ci_lo, mean_ci_hi = ci_hi) %>% mutate(outcome = "Days between\n final discharge and death")
  ) %>%
  mutate(outcome = factor(outcome, levels = unique(outcome)))

(fig_outcomes_by_year_pod <-
  ggplot(
      tbl_descriptives_outcomes_by_year_pod,
      aes(
        x = val_cohort_year,
        y = mean,
        shape = cat_place_of_death,
        group = cat_place_of_death,
        colour = cat_place_of_death
      )
    ) +
    facet_wrap(vars(outcome), scales = "free") +
    geom_point(size = rel(3)) +
    geom_line() +
    scale_colour_viridis_d(option = "D") +
    scale_y_continuous(limits = c(0,NA), breaks = scales::breaks_pretty(n=6)) +
    labs(x = NULL, y = NULL))

# png
ggsave(fig_outcomes_by_year_pod, filename = file.path(dir_output, "fig_outcomes_by_year_and_pod.png"), bg = "white", units = "cm", width = 15, height = 10, dpi = 600)

# eps
ggsave(fig_outcomes_by_year_pod, filename = file.path(dir_output, "fig_outcomes_by_year_and_pod.eps"), bg = "white", units = "cm", width = 15, height = 10)
```


# Number of individuals removed for missingness in models / STROBE diagram

```{r}
strobe_diagram <- tribble(
  ~name, ~entry, ~n,
  "1", "All individuals extracted", cohort_by_pod %>% filter(cat_place_of_death == "All") %>% pull(n) %>% sum,
  "2", "Home decedents", cohort_by_pod %>% filter(cat_place_of_death == "Home") %>% pull(n) %>% sum,
  "3", "Excluded: institutional decedents", cohort_by_pod %>% filter(!cat_place_of_death %in% c("Home","All")) %>% pull(n) %>% sum,
  "4", "Home decedents in model", 97948,
  "5", "Excluded: missing covariates", missingness_overall %>% pull(n) %>% sum,
  "6b", "Excluded: Home decedents without hospitalisations", no_hospitalisations %>% filter(cat_place_of_death=="Home") %>% pull(n) %>% sum,
  "6", "Home decedents with at least one hospitalisation", hosp_by_pod %>% filter(cat_place_of_death=="Home") %>% pull(n_users) %>% sum,
  "7","Home decedents with at least one hospitalisation in model", 60339,
  "8", "Excluded: missing covariates", (hosp_by_pod %>% filter(cat_place_of_death=="Home") %>% pull(n_users) %>% sum) - 60339,
)

# (fig_patient_flow <- ggflowchart(
#   data = tibble(from = as.character(c(1,1,2,2,2,6,6)), to = as.character(c(3,2,4,5,6,7,8))),
#   node_data = strobe_diagram %>% mutate(label = paste0(entry,"\n",scales::label_comma()(n)))
# ))
```

Below is a chunk of mermaid code to specify the flowchart; I ended up just designing it on mermaidchart.com and exported a png file from there.

```{mermaid, eval=FALSE}
---
config:
  theme: neo
  look: classic
  layout: dagre
---
flowchart TD
    A["All decedents, 
    N=351,145"] -- "Excluded:
    institutional decedents, 
    N=252,670" --> B["Home decedents, 
    N=98,475"]
    B -- "Excluded:
    missing covariates,
    N=527" --> C["**Models:
    days in hospital &
    number of 
    hospitalisations, 
    N=97,948**"]
    B -- "Excluded:
    no hospitalisations,
    N=37,937" --> D["Hospitalised, 
    N=60,538"]
    D -- "Excluded:
    missing covariates,
    N=199" --> E["**Model: days between
    final discharge & death,
    N=60,339**"]
```


# Compare coefficients

Note: this is for my own sense-checking of the results, and probably way too much detail to publish.
All the regression models aim to predict the mean outcome for each combination of covariates.

Note that I'm putting the intercept on a separate facet because that's the "grand mean" of the outcome when all covariates are set to 0, so it's much larger than the coefficients/

- The coefficients are very similar for all datasets between Poisson, Poisson with RSE (no surprises, just the CI is different!), and the Negative binomial models.
- For Days in hospital, there are some differences between model types:
  - age has the opposite effect between Poisson and Negbin models, as does Covid-19 as the cause of death; the effect of Married marstat is bigger in the negbin model than poisson, as is SINMD quintile 5, male sex, pandemic period; some effects are drastically smaller in negbin: age, circulatory CoD, Covid-19, COD, dementia CoD

<!-- For hospitalisations, the coefficients are very similar between Poisson, Negative binomial, and Zero-inflated Negative Binomial models (the conditional component, rather than the zero-inflated component) -->

```{r}
list(
  "poisson" = model_coefficients_poisson,
  "poisson_rse" = model_coefficients_rse,
  "negbin" = model_coefficients_negbin
  ) %>%
  list_rbind(names_to = "model_type") %>%
  mutate(
    dataset = case_when(
      str_detect(model, "hosp\\_") ~ "Hospitalisations",
      str_detect(model, "los\\_") ~ "Days in hospital",
      str_detect(model, "discharge\\_") ~ "Days between discharge & death",
    )
  ) %>%
  # filter(str_detect(model, "hosp\\_")) %>%
  # filter(is.na(Component) | Component == "conditional") %>%
  mutate(
  #   IRR = coalesce(IRR, exp_coef),
  #   IRR_CI_low = coalesce(IRR_CI_low, exp_CI_low),
  #   IRR_CI_high = coalesce(IRR_CI_high, exp_CI_high),
    intercept = variable=="(Intercept)"
  ) %>%
  ggplot(
    aes(x = IRR, y = paste0(variable,": ",level), xmin = IRR_CI_low, xmax = IRR_CI_high, shape = model_type)
  ) +
  geom_vline(xintercept = 1, linetype = "dashed", colour = "grey75") +
  geom_point(size = rel(2), position = position_dodge(width = 1)) +
  geom_linerange(position = position_dodge(width = 1)) +
  facet_wrap(vars(intercept, dataset), scales = "free", nrow = 2) +
  NULL
```


# Compare AMEs

This is the main way I'm comparing between the different models since they adopt different methods: to compare between the zero-inflated negative binomial and all the others a common basis is needed, because the zero-inflated model produces 2 sets of coefficients, and they are not easily comparable

## Days between discharge & death

```{r}
# TODO: the CIs on the Poisson look too small, plus it looks like the RSE versions of the Poisson AMEs aren't there?!
# TODO: check the SH to see if something went wrong when computing these?
# TODO: maybe change HC0 to HC3, or just set it to "sandwich" or whatever the default is? I just want a HC estimator of variance, don't really care which

model_ames %>%
  separate_wider_regex(cols = model, patterns = c(dataset = "los|discharge|hosp", ".*", model_type = "negbin|poisson\\_rse|poisson|ols|zinb")) %>%
  ggplot(
    aes(x = estimate, y = paste0(term,": ",contrast), shape = model_type, xmin = conf.low, xmax = conf.high)
  ) +
  geom_point(size = rel(2), position = position_dodge(width = 1)) +
  geom_linerange(position = position_dodge(width = 1)) +
  facet_wrap(vars(dataset), scales = "free")
```

# Pretty coefficient tables

## Poisson + RSE

```{r}
(tbl_model_coefficients_poisson_rse <-
  model_coefficients_rse %>%
  mutate(
    variable = replace_with_long_variable_name(variable),
    p_pretty = scales::label_pvalue()(p),
    stars = gtools::stars.pval(p),
    IRR = paste0(signif(IRR, 3), stars),
    ci = format_ci(IRR_CI_low, IRR_CI_high),
    ) %>%
  select(c(model, variable, level, IRR, ci)) %>%
  mutate(model = str_remove(model, "\\_poisson\\_rse")) %>%
  pivot_wider(names_from = model, values_from = c(IRR, ci), names_vary = "slowest"))

tbl_model_coefficients_poisson_rse %>%
  mutate(variable = if_else(condition = duplicated(variable), true = " ", false = as.character(variable))) %>%
  write_csv(., file = file.path(dir_output, "tbl_model_coefficients_poisson_rse.csv"))
```


## Negbin

```{r}
(tbl_model_coefficients_negbin <-
  model_coefficients_negbin %>%
  mutate(
    variable = replace_with_long_variable_name(variable),
    p_pretty = scales::label_pvalue()(p),
    stars = gtools::stars.pval(p),
    IRR = paste0(signif(IRR, 3), stars),
    ci = format_ci(IRR_CI_low, IRR_CI_high),
    ) %>%
  select(c(model, variable, level, IRR, ci)) %>%
  mutate(model = str_remove(model, "\\_poisson\\_rse")) %>%
  pivot_wider(names_from = model, values_from = c(IRR, ci), names_vary = "slowest"))

tbl_model_coefficients_negbin %>%
  mutate(variable = if_else(condition = duplicated(variable), true = " ", false = as.character(variable))) %>%
  write_csv(., file = file.path(dir_output, "tbl_model_coefficients_negbin.csv"))
```

# Pretty AME table

## Poisson + RSE

```{r}
(tbl_ames_poisson_rse <-
  model_ames %>%
  filter(str_detect(model, "\\_rse")) %>%
  mutate(
    term = 
      replace_with_long_variable_name(term) %>%
      factor(., levels = unique(tbl_model_coefficients_poisson_rse$variable)),
    p_pretty = scales::label_pvalue()(p.value),
    stars = gtools::stars.pval(p.value),
    stars = str_remove(stars, "\\.$"),
    AME = paste0(signif(estimate), stars),
    ci = format_ci(conf.low, conf.high, sep = ","),
    ) %>%
  select(c(model, term, contrast, AME, ci)) %>%
  mutate(model = str_remove(model, "\\_poisson\\_rse")) %>%
  pivot_wider(names_from = model, values_from = c(AME, ci), names_vary = "slowest") %>%
  arrange(term))

tbl_ames_poisson_rse %>%
  mutate(term = if_else(condition = duplicated(term), true = " ", false = as.character(term))) %>%
  write_csv(., file = file.path(dir_output, "tbl_ames_poisson_rse.csv"))
```

# Compute total sample size for models

```{r}
(sample_size_los_and_hosp <- 
  cohort_by_pod %>%
  filter(str_detect(cat_place_of_death, "^Home")) %>%
  left_join(missingness_home %>% select(val_cohort_year, any_missing), join_by(val_cohort_year)) %>%
  mutate(total_n = n - parse_number(any_missing))
)

(total_sample_los_and_hosp = sum(sample_size_los_and_hosp$total_n))

(total_sample_discharge = total_sample_los_and_hosp - 37609)  # this is a bit ugly - the 37609 figure is the number of 0 hospitalisations reported in part 2 modeling hospitalisations, in the distributional checks (overdispersion)

```

# Univariate regression coefficients

## Poisson + RSE

```{r}
tbl_univariate_poisson_rse <-
  univariate_regression_poisson_rse %>%
    filter(str_detect(model, pattern = "los|hosp|discharge") & variable!="(Intercept)") %>%
  mutate(
    variable = replace_with_long_variable_name(variable),
    p_pretty = scales::label_pvalue()(p.value),
    stars = gtools::stars.pval(p.value),
    IRR = paste0(signif(estimate, 3), stars),
    ci = format_ci(conf.low, conf.high, sep = ","),
    model = str_extract(model, "los|hosp|discharge"),
    level = if_else(level=="", " ", level)
    ) %>%
  select(model, variable, level, IRR, ci) %>%
  pivot_wider(names_from = model, values_from = c(IRR, ci), names_vary = "slowest") %>%
  # keep only first occurence of variable, replace with blanks further down
  mutate(variable = if_else(
      condition = duplicated(variable),
      true = " ",
      false = as.character(variable)
    ))

tbl_univariate_poisson_rse %>%
  write_csv(., file = file.path(dir_output, "tbl_univariate_coefs_rse.csv"))
```

# Combined univariate & adjusted regression coefficient tables, one per outcome; Poisson + RSE

```{r}
# TODO: separate this out into table and writing steps
tbls_uni_and_adjusted_rse <- pmap(
  .l = tribble(
    ~model_short, ~filename,
    "los", "tbl_uni_and_adjusted_poisson_rse_los",
    "hosp", "tbl_uni_and_adjusted_poisson_rse_hosp",
    "discharge", "tbl_uni_and_adjusted_poisson_rse_discharge",
  ),
  .f = function(model_short, filename) {
    bind_rows(
      univariate_regression_poisson_rse %>%
      filter(str_detect(model, pattern = model_short) & variable!="(Intercept)") %>% mutate(regression = "uni") %>%
      transmute(
        regression, model, variable, level, 
        IRR = paste0(signif(estimate, 3), gtools::stars.pval(p.value)) %>% str_remove(., "\\.$"),
        ci = format_ci(conf.low, conf.high)
      ),
      model_coefficients_rse %>% filter(str_detect(model, pattern = model_short)) %>% mutate(regression = "adj") %>%
      transmute(
        regression, model, variable, level, 
        IRR = paste0(signif(IRR, 3), gtools::stars.pval(p)) %>% str_remove(., "\\.$"),
        ci = format_ci(IRR_CI_low, IRR_CI_high)
      ),
      # model_ames %>% filter(str_detect(model, pattern = "poisson\\_rse")) %>% filter(str_detect(model, pattern = model_short)) %>% mutate(regression = "ame") %>%
      #   transmute(
      #     regression, # TODO: make this the same shape as the regression?
      #   )
    ) %>%
    mutate(
      level = replace_na(level, replace = ""),  # for consistency, and also to not confuse excel
      variable = replace_with_long_variable_name(variable),
      variable = factor(variable, levels = unique(tbl_model_coefficients_poisson_rse$variable)),
      model = str_remove(model, "\\_poisson\\_rse")
      ) %>%
    pivot_wider(names_from = c(regression,model), values_from = c(IRR, ci), names_vary = "slowest") %>%
    arrange(variable)
  }
)

walk2(
  .x = tbls_uni_and_adjusted_rse,
  .y = c("tbl_uni_and_adjusted_poisson_rse_los","tbl_uni_and_adjusted_poisson_rse_hosp", "tbl_uni_and_adjusted_poisson_rse_discharge"),
  .f = function(tbl, filename) {
    tbl %>% mutate(variable = if_else(  # keep only 1st occurence of variable, replace with blanks
      condition = duplicated(variable),
      true = " ",
      false = as.character(variable)
    )) %>%
      write_csv(., file = file.path(dir_output, paste0(filename, ".csv")))
  }
)
```

# Sensitivity checks: negative binomial model regression

For this, I'll report univariate, adjusted, and AME in one table for all three models

```{r}
tbl_negbin_combined <-
  bind_rows(
    # univariate
    univariate_regression_poisson_rse %>%
      filter(str_detect(model, pattern = "los|hosp|discharge") & variable!="(Intercept)") %>%
    mutate(
      measure = factor("uni", levels = c("uni","adj","ame")),
      variable = replace_with_long_variable_name(variable),
      p_pretty = scales::label_pvalue()(p.value),
      stars = gtools::stars.pval(p.value),
      estimate = paste0(signif(estimate, 3), stars),
      ci = format_ci(conf.low, conf.high, sep = ","),
      model = str_extract(model, "los|hosp|discharge"),
      level = if_else(level %in% c("", NA), " ", level)
      ) %>%
      select(measure, model, variable, level, estimate, ci),
    # adjusted
    model_coefficients_negbin %>%
      mutate(
        measure = factor("adj", levels = c("uni","adj","ame")),
        variable = replace_with_long_variable_name(variable),
        p_pretty = scales::label_pvalue()(p),
        stars = gtools::stars.pval(p),
        estimate = paste0(signif(IRR, 3), stars),
        ci = format_ci(IRR_CI_low, IRR_CI_high, sep = ","),
        model = str_extract(model, "los|hosp|discharge"),
        level = if_else(level %in% c("", NA), " ", level)
      ) %>%
      select(measure, model, variable, level, estimate, ci),
    # AME
    model_ames %>%
      filter(str_detect(model, "negbin")) %>%
      mutate(
        measure = factor("ame", levels = c("uni","adj","ame")),
        variable = replace_with_long_variable_name(term),
        # a slightly ugly way of finding the same levels
        level = approx_match_by_first_word(contrast, unique(model_coefficients_negbin$level)),
        p_pretty = scales::label_pvalue()(p.value),
        stars = gtools::stars.pval(p.value),
        estimate = paste0(signif(estimate, 3), stars),
        ci = format_ci(conf.low, conf.high, sep = ","),
        model = str_extract(model, "los|hosp|discharge"),
        level = if_else(level %in% c("", NA), " ", level)
      ) %>%
      select(measure, model, variable, level, estimate, ci)
  ) %>%
  mutate(
    model = factor(model, levels = c("los","hosp","discharge")),
    variable = factor(variable, levels = unique(tbl_model_coefficients_poisson_rse$variable))) %>%
  arrange(model, measure, variable)

tbl_negbin_combined %>%
  # pivot on measure, so columns are univariate, adjusted, and AME, and rows are the three outcomes
  pivot_wider(names_from = measure, values_from = c(estimate, ci), names_vary = "slowest") %>%
  arrange(model, variable) %>%
  # keep only first occurence of variable, replace with blanks further down
  group_by(model) %>%
  mutate(variable = if_else(
      condition = duplicated(variable),
      true = " ",
      false = as.character(variable)
    )) %>%
  ungroup %>%
  write_csv(., file = file.path(dir_output, "tbl_negbin_uni_adj_ame_sensitivity_check.csv"))
```

